{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1VX5NZTSe-W6mMN1HLdCIOsRmEmO6gll1","authorship_tag":"ABX9TyNSFYDZZEV1EtN8bDPDxnaN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%%capture --no-stderr\n","%pip install -U chromadb"],"metadata":{"id":"Kw3v_r9cVhrf","executionInfo":{"status":"ok","timestamp":1751328899088,"user_tz":240,"elapsed":6133,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import requests\n","from urllib.parse import urlparse\n","import chromadb\n","from chromadb.config import Settings\n","from chromadb.utils import embedding_functions\n","from openai import OpenAI\n","from tiktoken import encoding_for_model\n","from pydantic import BaseModel\n","import json"],"metadata":{"id":"mkRGblRBVIGl","executionInfo":{"status":"ok","timestamp":1751328905644,"user_tz":240,"elapsed":4595,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Path setting\n","dir_path = '/content/drive/MyDrive/Colab_Notebooks/'\n","\n","# API keys\n","openai_file = \"googlecolab_openai_key.txt\"\n","with open(dir_path + openai_file, \"r\") as file:\n","    openai_api_key = file.read()\n","\n","if not os.environ.get(\"OPENAI_API_KEY\"):\n","    os.environ[\"OPENAI_API_KEY\"] = openai_api_key"],"metadata":{"id":"yiw-PnpOVm6H","executionInfo":{"status":"ok","timestamp":1751328913281,"user_tz":240,"elapsed":120,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Set OpenAI client and Chorma client\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n","chroma_client = chromadb.PersistentClient(path=dir_path+\"+repo_search/chroma_db\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAnkQi4rVoP8","executionInfo":{"status":"ok","timestamp":1751328925711,"user_tz":240,"elapsed":655,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}},"outputId":"cfd02ea9-eca5-4538-a58e-d74b8c267fda"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"]}]},{"cell_type":"code","source":["# chroma_client.delete_collection(\"example_collection\")"],"metadata":{"id":"Y8bbbGi5VvHF","executionInfo":{"status":"ok","timestamp":1751328965874,"user_tz":240,"elapsed":71,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Embedding model\n","default_ef = embedding_functions.DefaultEmbeddingFunction() # by default, all-MiniLM-L6-v2"],"metadata":{"id":"Yyn32uAAVuH8","executionInfo":{"status":"ok","timestamp":1751328974465,"user_tz":240,"elapsed":19,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Information on repo to search.\n","# In the function 'get_contents', need the info for api_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"\n","owner=\"woo1976\"\n","repo=\"jenkins-python-test\"\n","path=\"\"\n","branch=\"master\""],"metadata":{"id":"FWtcU5VQV2Wc","executionInfo":{"status":"ok","timestamp":1751328985069,"user_tz":240,"elapsed":25,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Functions\n","def get_repo_info(repo_url):\n","    \"\"\"\n","    Extract the owner and repository name from the GitHub URL.\n","    \"\"\"\n","    parsed_url = urlparse(repo_url)\n","    path_parts = parsed_url.path.strip('/').split('/')\n","    if len(path_parts) < 2:\n","        raise ValueError(\"Invalid GitHub repository URL.\")\n","    owner = path_parts[0]\n","    repo = path_parts[1].replace('.git', '')\n","    return owner, repo\n","\n","def get_file_content(download_url):\n","    \"\"\"\n","    Retrieve the raw content of a file.\n","    \"\"\"\n","    response = requests.get(download_url)\n","    response.raise_for_status()\n","    return response.text\n","\n","def get_contents(owner=\"woo1976\", repo=\"jenkins-python-test\", path=\"\", branch=\"master\"):\n","    \"\"\"\n","    Recursively retrieve the contents of the repository, excluding image and media files.\n","    \"\"\"\n","    api_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"\n","    params = {\"ref\": branch}  # You can change the branch if needed\n","    response = requests.get(api_url, params=params)\n","    response.raise_for_status()\n","    items = response.json()\n","    contents = []\n","\n","    if not isinstance(items, list):\n","        items = [items]\n","\n","    # Exclude image and media formats\n","    excluded_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.mp4', '.mp3', '.wav', '.avi', '.mov']\n","\n","    for item in items:\n","        if item['type'] == 'file' and any(item['path'].endswith(ext) for ext in excluded_extensions):\n","            continue\n","\n","        if item['type'] == 'file':\n","            file_content = get_file_content(item['download_url'])\n","            contents.append({\n","                'type': 'file',\n","                'path': item['path'],\n","                'content': file_content\n","            })\n","        elif item['type'] == 'dir':\n","            dir_contents = get_contents(owner, repo, item['path'], branch)\n","            contents.append({\n","                'type': 'dir',\n","                'path': item['path'],\n","                'contents': dir_contents\n","            })\n","    return contents\n","\n","def flatten_contents(contents):\n","    \"\"\"\n","    Flatten the nested contents into a list of files with paths and contents.\n","    \"\"\"\n","    flat_files = []\n","\n","    def _flatten(items):\n","        for item in items:\n","            if item['type'] == 'file':\n","                flat_files.append({\n","                    'path': item['path'],\n","                    'content': item['content']\n","                })\n","            elif item['type'] == 'dir':\n","                _flatten(item['contents'])\n","\n","    _flatten(contents)\n","    return flat_files\n","\n","def truncate_to_token_limit(text, max_tokens, encoding='gpt-4o'):\n","    \"\"\"\n","    Truncate the text to fit within the specified token limit.\n","    \"\"\"\n","    tokenizer = encoding_for_model(encoding)\n","    tokens = tokenizer.encode(text)\n","    if len(tokens) <= max_tokens:\n","        return text\n","    truncated_tokens = tokens[:max_tokens]\n","    return tokenizer.decode(truncated_tokens)\n","\n","def summarize_text(text, max_tokens=200):\n","    \"\"\"\n","    Summarize the text to fit within a limited number of tokens.\n","    \"\"\"\n","    prompt = f\"Summarize the following text to {max_tokens} tokens:\\n\\n{text}\\n\\nSummary:\"\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text.\"},\n","            {\"role\": \"user\", \"content\": prompt}\n","        ],\n","        max_tokens=max_tokens,\n","        temperature=0.5\n","    )\n","    return response.choices[0].message.content.strip()\n","\n","def generate_gpt4o_response(query, context_docs, max_context_tokens=6000):\n","    \"\"\"\n","    Generate a response using OpenAI's GPT-4o based on the query and retrieved context documents.\n","    \"\"\"\n","    # Summarize to reduce token size\n","    summarized_contexts = [summarize_text(doc, max_tokens=200) for doc in context_docs]\n","\n","    # Combine into a single string\n","    combined_context = \"\\n\\n\".join(summarized_contexts)\n","\n","    # Truncate\n","    context = truncate_to_token_limit(combined_context, max_context_tokens)\n","\n","    prompt = f\"\"\"You are an assistant that provides detailed answers based on the following context.\n","The answer should include the most relevant file name and its path. It would be also better to include summary of the file.\n","Lastly, it would be best to have the most relevant code snippet from the script:\n","\n","Context:\n","{context}\n","\n","Question:\n","{query}\n","\n","Answer:\"\"\"\n","\n","    try:\n","        response = client.beta.chat.completions.parse(\n","            model=\"gpt-4o\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ],\n","            max_tokens=1000,\n","            temperature=0.2,\n","            response_format=ResFormat,\n","        )\n","        answer = response.choices[0].message.content\n","        json_answer = json.loads(answer)\n","\n","        return json_answer\n","\n","    except Exception as e:\n","        print(f\"Error generating GPT-4o response: {e}\")\n","        return \"I'm sorry, I couldn't process your request at the moment.\""],"metadata":{"id":"3N5WiOueV47m","executionInfo":{"status":"ok","timestamp":1751329007601,"user_tz":240,"elapsed":81,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Define a structured output for LLM results\n","class ResFormat(BaseModel):\n","    file_name: str\n","    file_path: str\n","    summary: str\n","    code_snippet: str\n","\n","#  Extract repo contents\n","res = get_contents(owner=owner, repo=repo, path=path, branch=branch)\n","flat_files = flatten_contents(res)\n","\n","texts = [file['content'] for file in flat_files]\n","metadatas = [{'path': file['path']} for file in flat_files]\n","ids = [file['path'] for file in flat_files]\n","\n","# Create vector DB\n","collection = chroma_client.get_or_create_collection(name=\"example_collection\", embedding_function=default_ef)\n","collection.add(documents=texts, metadatas=metadatas, ids=ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQXJv70SV-bQ","executionInfo":{"status":"ok","timestamp":1751329025753,"user_tz":240,"elapsed":6590,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}},"outputId":"1ee96be2-c9f1-4fa3-f83f-ec7f5b8205f4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n","ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"]}]},{"cell_type":"code","source":["# Query results\n","query = \"Give me the script name having the python code test. It would be better for the script to have library import and function details.\"\n","top_k = 5\n","results = collection.query(\n","        query_texts=[query],\n","        n_results=top_k\n","    )\n","\n","retrieved_docs_with_metadata = []\n","for i in range(len(results['documents'][0])):\n","  doc = results['documents'][0][i]\n","  metadata = results['metadatas'][0][i]\n","  retrieved_docs_with_metadata.append({'document': doc, 'metadata': metadata})\n","context_docs = [doc for doc in retrieved_docs_with_metadata]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0c0_1cXWBQu","executionInfo":{"status":"ok","timestamp":1751329053291,"user_tz":240,"elapsed":499,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}},"outputId":"58327344-9297-4ad5-9029-321bb06aa853"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"]}]},{"cell_type":"code","source":["# Generate LLM agent answers\n","answer = generate_gpt4o_response(query, context_docs)"],"metadata":{"id":"a-8-QABEWJbf","executionInfo":{"status":"ok","timestamp":1751329080161,"user_tz":240,"elapsed":18956,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(answer['file_name'])\n","print(answer['file_path'])\n","print(answer['summary'])\n","print(answer['code_snippet'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4alt2c9WLh9","executionInfo":{"status":"ok","timestamp":1751329084943,"user_tz":240,"elapsed":16,"user":{"displayName":"Hakwoo Kim","userId":"12038205012716225125"}},"outputId":"affb3998-0be3-4d58-c6a6-c8ffd361e457"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["test_iris.py\n","tests/test_iris.py\n","This is a Python test script using the `pytest` framework and `click.testing`'s `CliRunner` to test a command-line interface (CLI) for the `irisvmpy` package. It defines a `TestCLI` class with a `runner` fixture that provides a `CliRunner` instance for running CLI commands. The script includes a test method, `test_print_help_succeeds`, which checks if invoking the `iris` CLI with the `--help` option executes successfully. The test asserts that the exit code is `0`, indicating that the help command runs without errors.\n","import pytest\n","from click.testing import CliRunner\n","\n","class TestCLI:\n","    @pytest.fixture\n","    def runner(self):\n","        return CliRunner()\n","\n","    def test_print_help_succeeds(self, runner):\n","        result = runner.invoke(cli, ['--help'])\n","        assert result.exit_code == 0\n"]}]}]}